env_type: 'gym' # gym, custom
env_name: 'Freeway-ram-v0' # if custom anyname is OK
# custom_env: 'stock_env.py'

nn_mod: 'dist_dqn' # must match with network_models counts
network_models: ['DistDQN']
optimizer: 'adam'
learning_rate: 6.e-4
epochs: 2000
flip_res: False # 
multi_procs: False
num_multi_procs: 1
loss_fn: 'dist-cross-entropy' # actor-critic, dist-cross-entropy
state_norm: True
test_interval: 100
target_nn: True # shows stable loss reduction, non target and non bootstrap may incur no train
# t_update: 25 
t_update: 10
bootstrap: True # shows unstable loss but not impact on test performance

n_step_mode: False
n_step: 100

replay_mode: True
ep_buffer_size: 200

# dist DQN
dist_support_limit: [-10., 10.]
support_div: 51
dist_network_dim: [128, 100, 25, 51] # 4
# dist_network_dim: [128, 200, 100, 51] # 4
dist_gamma: 0.8
action_space: 3

# exploration
prob_q: True # wheter q value is distributed probability for vqlue_nn
policy: 'greedy' #greedy, softmax, mix
epsilon: 0.2
epsilon_min: 0.05
epsilon_thrs: 200

# experience priority
exp_priority: True
priority_level: 5

# shuffle experience
sampled_batch: True
batch_size: 50



